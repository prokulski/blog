{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/55142677/sklearn-pipeline-pass-a-parameter-to-a-custom-transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pierszej części zobaczyliśmy jak zbudować *pipeline* dla danych i modeli. Dzięki temu dostaliśmy możliwość zmiany sposobu transformacji danych i zmiany modeli w ramach prostego, zwartego kodu. Ale co jeśli potrzebujemy jakiś *transformator* którego nie ma w pakietach?\n",
    "\n",
    "Dzisiaj napiszemy własny (a raczej poznamy mechanikę działania) oraz nauczymy się szukać najlepszych hyper parametrów dla modelu (właściwie: całego pipeline) w zwarty sposób."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak poprzednio - nasze działania oprzemy na Pythonie i pakiecie scikit learn. Podobne rozwiązania można znaleść w R (jeśli tego szukasz - zainteresuj się [Tidymodels](https://www.tidymodels.org/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez tego nie ma data science! ;)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "# modele\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# preprocessing - bazowe klasy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby zobaczyć co się dzieje wewnątrz kolejnych budowanych przez nas metod zbudujemy sobie prosty zestaw danych. W dzisiejszym ćwiczeniu nie chodzi o znalezienie konkretnego modelu czy też najlepszego wyniku - dane mogą być więc dowolne, ważne żebyśmy widzieli na nich efekty działań naszego kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cechy\n",
    "X = pd.DataFrame({\"Title\": [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\"],\n",
    "                  \"Body\": [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\"],\n",
    "                  \"Code\": [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\"]})\n",
    "# odpowiedź\n",
    "y = np.array([1.,0.,1.,0.,1.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Własny transformer/estymator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budujemy pierwszy *transformer*. Tutaj przyda się podstawowa wiedza na temat programowania obiektowego - co to jest klasa, co to są metody tej klasy, co to jest dziedziczenie i jak to wygląda w Pythonie. Zakładam, że znasz te podstawy.\n",
    "\n",
    "Nasz *transformer* potrzebuje dwóch metod: `fit()` oraz `transform()`. Wiemy jak działają transformery i modele w scikit-learn, prawda? Uczymy je na danych treningowych poprzez wywołanie metody `fit()` a potem stosujemy przekaształcenie do danych treningowych poprzez `transform()` (często stosuje się też od razu uczenie i przekaształcenie wywołując `fit_transform()`), zaś dane testowe (czy też nowe dane) traktujemy jedynie przez `transfor()`.\n",
    "\n",
    "Często modele/transformery mają jakieś parametry. Podaje się je podczas budowania klasy - czyli wywołuje się *konstruktora* klasy `__init__()` z odpowiednimi patametrami. Konstruktor \"zapamiętuje\" w ramach obiektu te parametry (w Pythonie jest to po prostu ustawienie wartości zmiennych `self.cośtam` dostępnych w ramach całego obiektu). Tak wygląda teoria, konkrety tłumaczy kod poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, param_a = [], param_b = 1):\n",
    "        \"\"\"\n",
    "        Konstruktor naszego obiektu MyTransformer.\n",
    "        \n",
    "        Przyjmuje dwa parametry:\n",
    "        * param_a - lista\n",
    "        * param_b - wartość liczbowa, domyślnie równa 1\n",
    "        \"\"\"\n",
    "\n",
    "        # zapamiętujemy hyper paramtery w ramach obiektu\n",
    "        self.param_a = param_a\n",
    "        self.param_b = param_b\n",
    "\n",
    "        # tą wartość \"wyprodukuje\" metoda fit()\n",
    "        self.fitted = None\n",
    "\n",
    "        # wypisujemy co się dzieje\n",
    "        print(\"\\n= LOG BEG =========================\")\n",
    "        print(\"MyTransformer.__init__():\")\n",
    "        print(f\"param_a:\\n{self.param_a}\\n\")\n",
    "        print(f\"param_b:\\n{self.param_b}\\n\")\n",
    "        print(f\"fitted:\\n{self.fitted}\")\n",
    "        print(\"= LOG END =========================\\n\")\n",
    "\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"\n",
    "        Metoda ta powinna \"nauczyć\" parametry w ramach obiektu.\n",
    "        Tutaj parametry te są losowo nadane.\n",
    "        \n",
    "        Pobiera paramety:\n",
    "        * x - cechy\n",
    "        * y - odpowiedź (ważne dla modelu, przy transformacji bez znaczenia) \n",
    "        \"\"\"\n",
    "\n",
    "        # ustalamy parametry transformatora - jedna losowa liczba 0 lub 1\n",
    "        self.fitted = np.round(np.random.random(1))\n",
    "\n",
    "        # wypisujemy co się dzieje i przy jakich parametrach\n",
    "        print(\"\\n= LOG BEG =========================\")\n",
    "        print(\"MyTransformer.fit():\")\n",
    "        print(f\"x:\\n{x}\\n\")\n",
    "        print(f\"y:\\n{y}\\n\")\n",
    "        print(f\"param_a:\\n{self.param_a}\\n\")\n",
    "        print(f\"param_b:\\n{self.param_b}\\n\")\n",
    "        print(f\"fitted:\\n{self.fitted}\")\n",
    "        print(\"= LOG END =========================\\n\")\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        Metoda zmienia dane, korzystając z wyuczonych w fit() parametrów.\n",
    "        \n",
    "        Tutaj zwróci tyle razy wartość wyuczoną w ramach fit() ile jest wierszy danych wejściowych\n",
    "        \"\"\"\n",
    "        \n",
    "        # szykujemy odpowiedź\n",
    "        ret_val = np.repeat(self.fitted, x.shape[0])\n",
    "\n",
    "        # wypisujemy co się dzieje\n",
    "        print(\"\\n= LOG BEG =========================\")\n",
    "        print(\"MyTransformer.transform():\")\n",
    "        print(f\"x:\\n{x}\\n\")\n",
    "        print(f\"y:\\n{y}\\n\")\n",
    "        print(f\"param_a:\\n{self.param_a}\\n\")\n",
    "        print(f\"param_b:\\n{self.param_b}\\n\")\n",
    "        print(f\"fitted:\\n{self.fitted}\\n\")\n",
    "        print(f\"ret_val:\\n{ret_val}\")\n",
    "        print(\"= LOG END =========================\\n\")\n",
    "\n",
    "        return ret_val\n",
    "\n",
    "    \n",
    "    def show_fitted(self):\n",
    "        \"\"\"\n",
    "        Ta metoda nie jest potrzebna, ale tutaj przyda się nam aby pokazać jaką wartość mają wyuczone parametry.\n",
    "        \"\"\"\n",
    "\n",
    "        print(self.fitted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając zbudowaną klasę możemy sprawdzić jak ona się zachowuje. Najpierw \"samodzielnie\", a później upakujemy ją w pipeline.\n",
    "\n",
    "Co się stanie jak utworzymy obiekt naszej klasy? Powinna wykonać się metoda `__init__()` - spróbujmy od razu podać parametry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.__init__():\n",
      "param_a:\n",
      "['a', 'b', 'c']\n",
      "\n",
      "param_b:\n",
      "123\n",
      "\n",
      "fitted:\n",
      "None\n",
      "= LOG END =========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obj = MyTransformer(param_a=['a', 'b', 'c'], param_b=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I zadziałało zgodnie z planem - wypisały się podane przez nas parametry, a *fitted* jest jeszcze nie zdefiniowany.\n",
    "Ale czy na pewno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "obj.show_fitted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zgadza się. Zatem wyuczmy (*dofitujmy*) nasz obiekt na danych przygotowanych wyżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.fit():\n",
      "x:\n",
      "  Title Body Code\n",
      "0    T1   B1   C1\n",
      "1    T2   B2   C2\n",
      "2    T3   B3   C3\n",
      "3    T4   B4   C4\n",
      "4    T5   B5   C5\n",
      "5    T6   B6   C6\n",
      "\n",
      "y:\n",
      "None\n",
      "\n",
      "param_a:\n",
      "['a', 'b', 'c']\n",
      "\n",
      "param_b:\n",
      "123\n",
      "\n",
      "fitted:\n",
      "[1.]\n",
      "= LOG END =========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyTransformer(param_a=['a', 'b', 'c'], param_b=123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "obj.show_fitted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystko się zgadza. A co się stanie jak zrobimy transformację?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.transform():\n",
      "x:\n",
      "  Title Body Code\n",
      "0    T1   B1   C1\n",
      "1    T2   B2   C2\n",
      "2    T3   B3   C3\n",
      "3    T4   B4   C4\n",
      "4    T5   B5   C5\n",
      "5    T6   B6   C6\n",
      "\n",
      "y:\n",
      "[1. 0. 1. 0. 1. 1.]\n",
      "\n",
      "param_a:\n",
      "['a', 'b', 'c']\n",
      "\n",
      "param_b:\n",
      "123\n",
      "\n",
      "fitted:\n",
      "[1.]\n",
      "\n",
      "ret_val:\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "= LOG END =========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poza wypisaniem jakichś parametrów obiektu dostaliśmy tablicę pięciu wartości równych temu co jest w *fitted*. I właśnie o to chodziło. Tutaj jest tablica długa na tyle na ile mamy rekordów w danych - musimy dostać listę, którą da się porówanać z wartościami Y naszych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ale miało być o pipeline'ach - zatem użymy naszego transformera, a za klasyfikator weźmiemy najprostrzy DummyClassifier() w dodatku skonfigurowany tak, aby zawsze odpowiadał wartością 0, nie ważne jakie są cechy konkretnej próbki (to ułatwi nam porównanie wyników)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.__init__():\n",
      "param_a:\n",
      "[1, 2, 3]\n",
      "\n",
      "param_b:\n",
      "10\n",
      "\n",
      "fitted:\n",
      "None\n",
      "= LOG END =========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "                ('preprocessor', MyTransformer(param_a=[1,2,3], param_b=10)),\n",
    "                ('classifier', DummyClassifier(strategy='constant', constant=0))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co się wydarzyło? A no tylko tyle, że wywołaliśmy konstruktora.\n",
    "\n",
    "Co zrobi *fitowanie* całego pipeline'u?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.fit():\n",
      "x:\n",
      "  Title Body Code\n",
      "0    T1   B1   C1\n",
      "1    T2   B2   C2\n",
      "2    T3   B3   C3\n",
      "3    T4   B4   C4\n",
      "4    T5   B5   C5\n",
      "5    T6   B6   C6\n",
      "\n",
      "y:\n",
      "[1. 0. 1. 0. 1. 1.]\n",
      "\n",
      "param_a:\n",
      "[1, 2, 3]\n",
      "\n",
      "param_b:\n",
      "10\n",
      "\n",
      "fitted:\n",
      "[1.]\n",
      "= LOG END =========================\n",
      "\n",
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.transform():\n",
      "x:\n",
      "  Title Body Code\n",
      "0    T1   B1   C1\n",
      "1    T2   B2   C2\n",
      "2    T3   B3   C3\n",
      "3    T4   B4   C4\n",
      "4    T5   B5   C5\n",
      "5    T6   B6   C6\n",
      "\n",
      "y:\n",
      "[1. 0. 1. 0. 1. 1.]\n",
      "\n",
      "param_a:\n",
      "[1, 2, 3]\n",
      "\n",
      "param_b:\n",
      "10\n",
      "\n",
      "fitted:\n",
      "[1.]\n",
      "\n",
      "ret_val:\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "= LOG END =========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor', MyTransformer(param_a=[1, 2, 3], param_b=10)),\n",
       "                ('classifier',\n",
       "                 DummyClassifier(constant=0, random_state=None,\n",
       "                                 strategy='constant'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonało się najpierw *fit()* a potem *transform()*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po *fitowaniu* możemy ocenić nasz model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= LOG BEG =========================\n",
      "MyTransformer.transform():\n",
      "x:\n",
      "  Title Body Code\n",
      "0    T1   B1   C1\n",
      "1    T2   B2   C2\n",
      "2    T3   B3   C3\n",
      "3    T4   B4   C4\n",
      "4    T5   B5   C5\n",
      "5    T6   B6   C6\n",
      "\n",
      "y:\n",
      "[1. 0. 1. 0. 1. 1.]\n",
      "\n",
      "param_a:\n",
      "[1, 2, 3]\n",
      "\n",
      "param_b:\n",
      "10\n",
      "\n",
      "fitted:\n",
      "[1.]\n",
      "\n",
      "ret_val:\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "= LOG END =========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy że wykonał się *transformer* z już wyuczonymi wartościami *fitted*. Odpowiedzią w tym przypadku jest *accuracy* - mamy do czynienia z modelem klasyfikującym.\n",
    "\n",
    "Oczywiście otrzymana wartość predykcji zależy od tego jak wylosował nam się w ramach *fit* parametr *fitted*, ale w **tym konkretnym przypadku** zawsze będziemy mieć 1/3 skuteczności (bo mamy 2 zera i 4 jedynki w danych, a DummyClassifier skonfigurowaliśmy tak, aby zawszse zwracał zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do czego to wszystko może być potrzebne?** Do kazdej sytuacji, w której nie mamy gotowego rozwiązania. Nie mamy (a przynajmniej nie kojarzę) transformatora który na przykład zamieni nam zapis liczb dziesiętnych z 12.345,67 na 12345.67 i zmieni otrzymaną wartość na *float*. Oczywiście przykłady można mnożyć - to jeden z najprostrzych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych hyper parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dobrze - wiemy jak przygotować swoje transformatory danych (spróbuj analogicznie przygotować estymatory!), a nawet dać im możliwość *kręcenia śrubkami* w postaci hyper parametrów. Ale jak znaleźć najlepszą kombinację hyper parametrów?\n",
    "\n",
    "Użyjemy przeszukiwania po siatce wszystkich parametrów. SciKit Learn ma to na dzień dobry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do tego ćwiczenia przygotujemy inną wersję naszego transformatora - takiego, który podczas *fittowania* niczego nie robi, ale podczas transformacji już coś się dzieje (i jest to zależne od hyper parametrów):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformerTwo(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param_a = [], param_b = 1):\n",
    "        self.param_a = param_a\n",
    "        self.param_b = param_b\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        titles = \",\".join(x.Title)\n",
    "        if np.sum(self.param_a)/(1+self.param_b) >= 10:\n",
    "            ret_val = np.zeros(x.shape[0])\n",
    "        else:\n",
    "            ret_val = np.ones(x.shape[0])\n",
    "        print(f\"x.shape: {x.shape} ({titles}) \\t\\t\\tparam_a: {self.param_a} \\t\\tparam_b: {self.param_b}\\t\\tret_val: {ret_val}\")\n",
    "        \n",
    "        return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie jak już wiele razy wcześniej - budujemy pipeline i siatkę parametrów do przeszukania. Dla naszego przykładu nie będziemy zmieniać parametrów klasyfikatora (i tak jak poprzenio zawsze dostaniemy jedynkę) - dzięki temu zobaczymy jakie są kolejne przebiegi po siatce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_two = Pipeline(steps=[\n",
    "    ('preprocessor', MyTransformerTwo()),\n",
    "    ('classifier', DummyClassifier(strategy='constant', constant=1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__param_a': [[1, 2, 3], [4, 5, 6]],\n",
    "    'preprocessor__param_b': [0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No to szukamy. Przy okazji (parametr *cv*) włączamy walidację krzyżową (*cross validation*) - dla każdej kombinacji parametrów podzielimy zbiór na dwa *foldy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 0\t\tret_val: [0. 0. 0.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 0\t\tret_val: [0. 0. 0.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 0\t\tret_val: [0. 0. 0.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 0\t\tret_val: [0. 0. 0.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T1,T2,T3) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (3, 3) (T4,T5,T6) \t\t\tparam_a: [4, 5, 6] \t\tparam_b: 1\t\tret_val: [1. 1. 1.]\n",
      "x.shape: (6, 3) (T1,T2,T3,T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        MyTransformerTwo(param_a=[],\n",
       "                                                         param_b=1)),\n",
       "                                       ('classifier',\n",
       "                                        DummyClassifier(constant=1,\n",
       "                                                        random_state=None,\n",
       "                                                        strategy='constant'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'preprocessor__param_a': [[1, 2, 3], [4, 5, 6]],\n",
       "                         'preprocessor__param_b': [0, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe_two, param_grid, cv=2)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy przebieg to jeden wiersz w powyższym listingu. I w wierszu tym widzimy które z elementów służyły jako dane treningowe oraz jakie hyper parametry zostały podane na \"rurociąg\". Nie widzimy wyniku modelu dla takich parametrów (za moment zobaczymy), ale możemy szybko znaleźć najlepszy wynik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszytkie wyniki oczywiście też. Ale uwaga - są to wartości dla danej kombinacji parametrów (odpowiednio uśrednione) a nie konkretnego przebiegu w ramach puli parametrów. To nawet lepiej - mamy wynik bardziej stabilny (uwzględniający *cross validation*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00272322, 0.00274515, 0.00234103, 0.00198877]),\n",
       " 'std_fit_time': array([2.82287598e-04, 5.45978546e-05, 4.63724136e-04, 3.40342522e-04]),\n",
       " 'mean_score_time': array([0.00185537, 0.00142717, 0.0010736 , 0.00106597]),\n",
       " 'std_score_time': array([2.11477280e-04, 1.33991241e-04, 1.57356262e-05, 3.81469727e-06]),\n",
       " 'param_preprocessor__param_a': masked_array(data=[list([1, 2, 3]), list([1, 2, 3]), list([4, 5, 6]),\n",
       "                    list([4, 5, 6])],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessor__param_b': masked_array(data=[0, 1, 0, 1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'preprocessor__param_a': [1, 2, 3], 'preprocessor__param_b': 0},\n",
       "  {'preprocessor__param_a': [1, 2, 3], 'preprocessor__param_b': 1},\n",
       "  {'preprocessor__param_a': [4, 5, 6], 'preprocessor__param_b': 0},\n",
       "  {'preprocessor__param_a': [4, 5, 6], 'preprocessor__param_b': 1}],\n",
       " 'split0_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667]),\n",
       " 'split1_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667]),\n",
       " 'mean_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667]),\n",
       " 'std_test_score': array([0., 0., 0., 0.]),\n",
       " 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dość długa ta lista, najprościej uzyskać zestaw najlepszych hyper parametrów przez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessor__param_a': [1, 2, 3], 'preprocessor__param_b': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenowany obiekt typu GridSearch() jest tym samym co wytrenowany pipeline czy też gotowy estymator, tak więc już na nim możemy użyć metod do predykcji (oczywiście skorzysta wtedy z najlepszych hyperparametrów):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (6, 3) (T1,T2,T3,T4,T5,T6) \t\t\tparam_a: [1, 2, 3] \t\tparam_b: 0\t\tret_val: [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wydawać się może dziwne, że wszystkie kombinacje parametrów dały 66% skuteczności. Ale spójrz na dobór próbek do *foldów* - mamy zestaw T1, T2 i T3 i drugi zestaw to T3, T4, T5. Patrząc na tabelę z danymi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Code</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>B6</td>\n",
       "      <td>C6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Body Code    y\n",
       "0    T1   B1   C1  1.0\n",
       "1    T2   B2   C2  0.0\n",
       "2    T3   B3   C3  1.0\n",
       "3    T4   B4   C4  0.0\n",
       "4    T5   B5   C5  1.0\n",
       "5    T6   B6   C6  1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['y'] = y\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "widać, że w tych kombinacjach zawsze mamy dwie jedynki i jedno zero (a DummyClassifier zawsze zwraca 1) więc zawsze w 2/3 \"pasuje\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
